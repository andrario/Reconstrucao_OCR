{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow script mode training and serving\n",
    "###  Modified From: \n",
    "#### Sagemaker Python SDK Examples: tensorflow_script_mode_training_and_serving.ipynb\n",
    "https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/tensorflow_script_mode_training_and_serving/tensorflow_script_mode_training_and_serving.ipynb\n",
    "\n",
    "Following modifications were made:  \n",
    "1. Incorporated scripts for local mode hosting  \n",
    "2. Added Train and Test Channels  \n",
    "3. Visualize results (confusion matrix and reports)  \n",
    "4. Added steps to deploy using model artifacts stored in S3  \n",
    "5. Iris model training\n",
    "\n",
    "Script mode is a training script format for TensorFlow that lets you execute any TensorFlow training script in SageMaker with minimal modification. The [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) handles transferring your script to a SageMaker training instance. On the training instance, SageMaker's native TensorFlow support sets up training-related environment variables and executes your training script. In this tutorial, we use the SageMaker Python SDK to launch a training job and deploy the trained model.\n",
    "\n",
    "Script mode supports training with a Python script, a Python module, or a shell script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the environment\n",
    "\n",
    "Let's start by setting up the environment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Mode Execution - requires docker compose configured\n",
    "#### The below setup script is from AWS SageMaker Python SDK Examples : tf-eager-sm-scriptmode.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!/bin/bash ./setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::223817798831:role/service-role/AmazonSageMaker-ExecutionRole-20200708T194212\n",
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "print(role)\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column_list_file = 'iris_train_column_list.txt'\n",
    "data_folder_name='data'\n",
    "train_filename = 'spa.txt'\n",
    "non_breaking_en = 'nonbreaking_prefix.en'\n",
    "non_breaking_es = 'nonbreaking_prefix.es'\n",
    "trainedmodel_path = 'trained_model'\n",
    "model_info_file = 'model_info.pth'\n",
    "input_vocab_file = 'in_vocab.pkl'\n",
    "output_vocab_file = 'out_vocab.pkl'\n",
    "\n",
    "train_file = os.path.abspath(os.path.join(data_folder_name, train_filename))\n",
    "non_breaking_en_file = os.path.abspath(os.path.join(data_folder_name, non_breaking_en))\n",
    "non_breaking_es_file = os.path.abspath(os.path.join(data_folder_name, non_breaking_es))\n",
    "trainedmodel_file = os.path.abspath(os.path.join(trainedmodel_path, non_breaking_es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your bucket name\n",
    "bucket_name = 'edumunozsala-ml-sagemaker'\n",
    "\n",
    "training_folder = r'transformer-nmt/train'\n",
    "output_folder = r'transformer-nmt'\n",
    "ckpt_folder = r'transformer-nmt/ckpt'\n",
    "\n",
    "training_data_uri = r's3://' + bucket_name + r'/' + training_folder\n",
    "output_data_uri = r's3://' + bucket_name + r'/' + output_folder\n",
    "ckpt_data_uri = r's3://' + bucket_name + r'/' + ckpt_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3://edumunozsala-ml-sagemaker/transformer-nmt/train',\n",
       " 's3://edumunozsala-ml-sagemaker/transformer-nmt',\n",
       " 's3://edumunozsala-ml-sagemaker/transformer-nmt/ckpt')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_uri,output_data_uri,ckpt_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://edumunozsala-ml-sagemaker/transformer-nmt/train/nonbreaking_prefix.es'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_session.upload_data(train_file,\n",
    "                              bucket=bucket_name, \n",
    "                              key_prefix=training_folder)\n",
    "\n",
    "sagemaker_session.upload_data(non_breaking_en_file,\n",
    "                              bucket=bucket_name, \n",
    "                              key_prefix=training_folder)\n",
    "\n",
    "sagemaker_session.upload_data(non_breaking_es_file,\n",
    "                              bucket=bucket_name, \n",
    "                              key_prefix=training_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sagemaker_session.upload_data(test_file, \n",
    "                              bucket=bucket_name, \n",
    "                              key_prefix=test_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a script for distributed training\n",
    "\n",
    "This tutorial's training script was adapted from TensorFlow's official [CNN MNIST example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/layers/cnn_mnist.py). We have modified it to handle the ``model_dir`` parameter passed in by SageMaker. This is an S3 path which can be used for data sharing during distributed training and checkpointing and/or model persistence. We have also added an argument-parsing function to handle processing training-related variables.\n",
    "\n",
    "At the end of the training job we have added a step to export the trained model to the path stored in the environment variable ``SM_MODEL_DIR``, which always points to ``/opt/ml/model``. This is critical because SageMaker uploads all the model artifacts in this folder to S3 at end of training.\n",
    "\n",
    "Here is the entire script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\r\n",
      "\u001b[37m#import sagemaker_containers\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmath\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mgc\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mre\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# To install tensorflow_datasets\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msubprocess\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minstall\u001b[39;49;00m(package):\r\n",
      "    subprocess.check_call([sys.executable, \u001b[33m\"\u001b[39;49;00m\u001b[33m-q\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m-m\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mpip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minstall\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, package])\r\n",
      "\r\n",
      "\u001b[37m# Install the library tensorflow_datasets\u001b[39;49;00m\r\n",
      "install(\u001b[33m'\u001b[39;49;00m\u001b[33mtensorflow_datasets\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mutils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m preprocess_text_nonbreaking, subword_tokenize\r\n",
      "\u001b[37m#from utils_train import loss_function, CustomSchedule\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmodel\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Transformer\r\n",
      "\r\n",
      "INPUT_COLUMN = \u001b[33m'\u001b[39;49;00m\u001b[33minput\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "TARGET_COLUMN = \u001b[33m'\u001b[39;49;00m\u001b[33mtarget\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "\u001b[37m#NUM_SAMPLES = 80000 #40000\u001b[39;49;00m\r\n",
      "\u001b[37m#MAX_VOCAB_SIZE = 2**14\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m#BATCH_SIZE = 64  # Batch size for training.\u001b[39;49;00m\r\n",
      "\u001b[37m#EPOCHS = 10  # Number of epochs to train for.\u001b[39;49;00m\r\n",
      "\u001b[37m#MAX_LENGTH = 15\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_train_data\u001b[39;49;00m(training_dir, nonbreaking_in, nonbreaking_out, train_file, nsamples):\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mGet the train data loader.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \u001b[37m# Load the nonbreaking files\u001b[39;49;00m\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(training_dir, nonbreaking_in), \r\n",
      "        mode = \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, encoding = \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        non_breaking_prefix_en = f.read()\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(training_dir, nonbreaking_out), \r\n",
      "        mode = \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, encoding = \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        non_breaking_prefix_es = f.read()\r\n",
      "\r\n",
      "    non_breaking_prefix_en = non_breaking_prefix_en.split(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    non_breaking_prefix_en = [\u001b[33m'\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + pref + \u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[34mfor\u001b[39;49;00m pref \u001b[35min\u001b[39;49;00m non_breaking_prefix_en]\r\n",
      "    non_breaking_prefix_es = non_breaking_prefix_es.split(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    non_breaking_prefix_es = [\u001b[33m'\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + pref + \u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[34mfor\u001b[39;49;00m pref \u001b[35min\u001b[39;49;00m non_breaking_prefix_es]\r\n",
      "    \u001b[37m# Load the training data\u001b[39;49;00m\r\n",
      "    \u001b[37m# Load the dataset: sentence in english, sentence in spanish \u001b[39;49;00m\r\n",
      "    df=pd.read_csv(os.path.join(training_dir, train_file), sep=\u001b[33m\"\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, header=\u001b[34mNone\u001b[39;49;00m, names=[INPUT_COLUMN,TARGET_COLUMN], usecols=[\u001b[34m0\u001b[39;49;00m,\u001b[34m1\u001b[39;49;00m], \r\n",
      "               nrows=nsamples)\r\n",
      "    \u001b[37m# Preprocess the input data\u001b[39;49;00m\r\n",
      "    input_data=df[INPUT_COLUMN].apply(\u001b[34mlambda\u001b[39;49;00m x : preprocess_text_nonbreaking(x, non_breaking_prefix_en)).tolist()\r\n",
      "    \u001b[37m# Preprocess and include the end of sentence token to the target text\u001b[39;49;00m\r\n",
      "    target_data=df[TARGET_COLUMN].apply(\u001b[34mlambda\u001b[39;49;00m x : preprocess_text_nonbreaking(x, non_breaking_prefix_es)).tolist()\r\n",
      "\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m input_data, target_data\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain_train\u001b[39;49;00m(dataset, transformer, n_epochs, print_every=\u001b[34m50\u001b[39;49;00m):\r\n",
      "  \u001b[33m''' Train the transformer model for n_epochs using the data generator dataset'''\u001b[39;49;00m\r\n",
      "  losses = []\r\n",
      "  accuracies = []\r\n",
      "  \u001b[37m# In every epoch\u001b[39;49;00m\r\n",
      "  \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(n_epochs):\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mStarting epoch \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(epoch+\u001b[34m1\u001b[39;49;00m))\r\n",
      "    start = time.time()\r\n",
      "    \u001b[37m# Reset the losss and accuracy calculations\u001b[39;49;00m\r\n",
      "    train_loss.reset_states()\r\n",
      "    train_accuracy.reset_states()\r\n",
      "    \u001b[37m# Get a batch of inputs and targets\u001b[39;49;00m\r\n",
      "    \u001b[34mfor\u001b[39;49;00m (batch, (enc_inputs, targets)) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(dataset):\r\n",
      "        \u001b[37m# Set the decoder inputs\u001b[39;49;00m\r\n",
      "        dec_inputs = targets[:, :-\u001b[34m1\u001b[39;49;00m]\r\n",
      "        \u001b[37m# Set the target outputs, right shifted\u001b[39;49;00m\r\n",
      "        dec_outputs_real = targets[:, \u001b[34m1\u001b[39;49;00m:]\r\n",
      "        \u001b[34mwith\u001b[39;49;00m tf.GradientTape() \u001b[34mas\u001b[39;49;00m tape:\r\n",
      "            \u001b[37m# Call the transformer and get the predicted output\u001b[39;49;00m\r\n",
      "            predictions = transformer(enc_inputs, dec_inputs, \u001b[34mTrue\u001b[39;49;00m)\r\n",
      "            \u001b[37m# Calculate the loss\u001b[39;49;00m\r\n",
      "            loss = loss_function(dec_outputs_real, predictions)\r\n",
      "        \u001b[37m# Update the weights and optimizer\u001b[39;49;00m\r\n",
      "        gradients = tape.gradient(loss, transformer.trainable_variables)\r\n",
      "        optimizer.apply_gradients(\u001b[36mzip\u001b[39;49;00m(gradients, transformer.trainable_variables))\r\n",
      "        \u001b[37m# Save and store the metrics\u001b[39;49;00m\r\n",
      "        train_loss(loss)\r\n",
      "        train_accuracy(dec_outputs_real, predictions)\r\n",
      "        \r\n",
      "        \u001b[34mif\u001b[39;49;00m batch % print_every == \u001b[34m0\u001b[39;49;00m:\r\n",
      "            losses.append(train_loss.result())\r\n",
      "            accuracies.append(train_accuracy.result())\r\n",
      "            \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mEpoch \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m Batch \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m Loss \u001b[39;49;00m\u001b[33m{:.4f}\u001b[39;49;00m\u001b[33m Accuracy \u001b[39;49;00m\u001b[33m{:.4f}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\r\n",
      "                epoch+\u001b[34m1\u001b[39;49;00m, batch, train_loss.result(), train_accuracy.result()))\r\n",
      "            \r\n",
      "    \u001b[37m# Checkpoint the model on every epoch        \u001b[39;49;00m\r\n",
      "    ckpt_save_path = ckpt_manager.save()\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving checkpoint for epoch \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m in \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(epoch+\u001b[34m1\u001b[39;49;00m,\r\n",
      "                                                        ckpt_save_path))\r\n",
      "    \u001b[37m#print(\"Time for 1 epoch: {} secs\\n\".format(time.time() - start))\u001b[39;49;00m\r\n",
      "    \u001b[37m# Save the model\u001b[39;49;00m\r\n",
      "    \u001b[37m#transformer.save(args.sm_model_dir, overwrite=True, save_format='tf')\u001b[39;49;00m\r\n",
      "    \r\n",
      "  \u001b[34mreturn\u001b[39;49;00m losses, accuracies\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mloss_function\u001b[39;49;00m(target, pred):\r\n",
      "    mask = tf.math.logical_not(tf.math.equal(target, \u001b[34m0\u001b[39;49;00m))\r\n",
      "    loss_ = loss_object(target, pred)\r\n",
      "    \r\n",
      "    mask = tf.cast(mask, dtype=loss_.dtype)\r\n",
      "    loss_ *= mask\r\n",
      "    \r\n",
      "    \u001b[34mreturn\u001b[39;49;00m tf.reduce_mean(loss_)\r\n",
      "\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mCustomSchedule\u001b[39;49;00m(tf.keras.optimizers.schedules.LearningRateSchedule):\r\n",
      "    \r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, d_model, warmup_steps=\u001b[34m4000\u001b[39;49;00m):\r\n",
      "        \u001b[36msuper\u001b[39;49;00m(CustomSchedule, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\r\n",
      "        \r\n",
      "        \u001b[36mself\u001b[39;49;00m.d_model = tf.cast(d_model, tf.float32)\r\n",
      "        \u001b[36mself\u001b[39;49;00m.warmup_steps = warmup_steps\r\n",
      "    \r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__call__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, step):\r\n",
      "        arg1 = tf.math.rsqrt(step)\r\n",
      "        arg2 = step * (\u001b[36mself\u001b[39;49;00m.warmup_steps**-\u001b[34m1.5\u001b[39;49;00m)\r\n",
      "        \r\n",
      "        \u001b[34mreturn\u001b[39;49;00m tf.math.rsqrt(\u001b[36mself\u001b[39;49;00m.d_model) * tf.math.minimum(arg1, arg2)\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "    \u001b[37m# Install tensorflow_datasets\u001b[39;49;00m\r\n",
      "    \u001b[37m#install('tensorflow_datasets')\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[37m# All of the model parameters and training parameters are sent as arguments when the script\u001b[39;49;00m\r\n",
      "    \u001b[37m# is executed. Here we set up an argument parser to easily access the parameters.\u001b[39;49;00m\r\n",
      "\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    \u001b[37m# Training Parameters\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minput batch size for training (default: 64)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--max-len\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m15\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minput max sequence length for training (default: 60)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m2\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 2)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--nsamples\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10000\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of samples to train (default: 20000)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# Data parameters                    \u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train_file\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[34mNone\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mTraining data file name\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--non_breaking_in\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[34mNone\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mNon breaking prefixes for input vocabulary\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--non_breaking_out\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[34mNone\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mNon breaking prefixes for output vocabulary\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mrandom seed (default: 1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# Model Parameters\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--d_model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mModel dimension (default: 64)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--ffn_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m128\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33msize of the FFN layer (default: 128)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--vocab_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10000\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33msize of the vocabulary (default: 10000)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--n_layers\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m4\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of layers (default: 4)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--n_heads\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m8\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of heads (default: 8)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--dropout_rate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.1\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mDropout rate (default: 0.1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# SageMaker Parameters\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--sm-model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--num-gpus\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "\r\n",
      "    args = parser.parse_args()\r\n",
      "\r\n",
      "    \u001b[37m#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\u001b[39;49;00m\r\n",
      "    \u001b[37m#print(\"Using device {}.\".format(device))\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(args.sm_model_dir, args.model_dir)\r\n",
      "    \u001b[37m# Load the training data.\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mGet the train data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    input_data, target_data = get_train_data(args.data_dir, args.non_breaking_in, args.non_breaking_out, args.train_file, args.nsamples)\r\n",
      "\r\n",
      "    \u001b[37m# Tokenize and pad the input sequences\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mTokenize the input and output data and create the vocabularies\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \r\n",
      "    encoder_inputs, tokenizer_inputs, num_words_inputs, sos_token_input, eos_token_input, del_idx_inputs= subword_tokenize(input_data, \r\n",
      "                                                                                                        args.vocab_size, args.max_len)\r\n",
      "    \u001b[37m# Tokenize and pad the outputs sequences\u001b[39;49;00m\r\n",
      "    decoder_outputs, tokenizer_outputs, num_words_output, sos_token_output, eos_token_output, del_idx_outputs = subword_tokenize(target_data,                                                                                                       args.vocab_size, args.max_len)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mInput vocab: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,num_words_inputs)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mOutput vocab: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,num_words_output)\r\n",
      "    \r\n",
      "    \u001b[37m# Define a dataset \u001b[39;49;00m\r\n",
      "    dataset = tf.data.Dataset.from_tensor_slices(\r\n",
      "                    (encoder_inputs, decoder_outputs))\r\n",
      "    dataset = dataset.shuffle(\u001b[36mlen\u001b[39;49;00m(input_data), reshuffle_each_iteration=\u001b[34mTrue\u001b[39;49;00m).batch(\r\n",
      "                    args.batch_size, drop_remainder=\u001b[34mTrue\u001b[39;49;00m)\r\n",
      "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\r\n",
      "\r\n",
      "    \u001b[37m# Clean the session\u001b[39;49;00m\r\n",
      "    tf.keras.backend.clear_session()\r\n",
      "    \u001b[37m# Create the Transformer model\u001b[39;49;00m\r\n",
      "    transformer = Transformer(vocab_size_enc=num_words_inputs,\r\n",
      "                          vocab_size_dec=num_words_output,\r\n",
      "                          d_model=args.d_model,\r\n",
      "                          n_layers=args.n_layers,\r\n",
      "                          FFN_units=args.ffn_dim,\r\n",
      "                          n_heads=args.n_heads,\r\n",
      "                          dropout_rate=args.dropout_rate)\r\n",
      "\r\n",
      "    \u001b[37m# Define a categorical cross entropy loss\u001b[39;49;00m\r\n",
      "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=\u001b[34mTrue\u001b[39;49;00m,\r\n",
      "                                                            reduction=\u001b[33m\"\u001b[39;49;00m\u001b[33mnone\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \u001b[37m# Define a metric to store the mean loss of every epoch\u001b[39;49;00m\r\n",
      "    train_loss = tf.keras.metrics.Mean(name=\u001b[33m\"\u001b[39;49;00m\u001b[33mtrain_loss\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \u001b[37m# Define a matric to save the accuracy in every epoch\u001b[39;49;00m\r\n",
      "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\u001b[33m\"\u001b[39;49;00m\u001b[33mtrain_accuracy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \u001b[37m# Create the scheduler for learning rate decay\u001b[39;49;00m\r\n",
      "    leaning_rate = CustomSchedule(args.d_model)\r\n",
      "    \u001b[37m# Create the Adam optimizer\u001b[39;49;00m\r\n",
      "    optimizer = tf.keras.optimizers.Adam(leaning_rate,\r\n",
      "                                     beta_1=\u001b[34m0.9\u001b[39;49;00m,\r\n",
      "                                     beta_2=\u001b[34m0.98\u001b[39;49;00m,\r\n",
      "                                     epsilon=\u001b[34m1e-9\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m#Create the Checkpoint \u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mCreating the checkpoint ...\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    ckpt = tf.train.Checkpoint(transformer=transformer,\r\n",
      "                           optimizer=optimizer)\r\n",
      "\r\n",
      "    ckpt_manager = tf.train.CheckpointManager(ckpt, \u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/checkpoints/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, max_to_keep=\u001b[34m1\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m#if ckpt_manager.latest_checkpoint:\u001b[39;49;00m\r\n",
      "    \u001b[37m#    ckpt.restore(ckpt_manager.latest_checkpoint)\u001b[39;49;00m\r\n",
      "    \u001b[37m#    print(\"Last checkpoint restored.\")\u001b[39;49;00m\r\n",
      "    \u001b[37m# to save the model in tf 2.1.0\u001b[39;49;00m\r\n",
      "    \u001b[37m#print('Preparing the model to be saved....')\u001b[39;49;00m\r\n",
      "    \u001b[37m#for enc_inputs, targets in dataset.take(1):\u001b[39;49;00m\r\n",
      "    \u001b[37m#    dec_inputs = targets[:, :-1]\u001b[39;49;00m\r\n",
      "    \u001b[37m#    print (enc_inputs.shape, dec_inputs.shape)\u001b[39;49;00m\r\n",
      "    \u001b[37m#    transformer._set_inputs(enc_inputs, dec_inputs, True)\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[37m# Train the model\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mTraining the model ....\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    losses, accuracies = main_train(dataset, transformer, args.epochs, \u001b[34m100\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# Save the while model\u001b[39;49;00m\r\n",
      "    \u001b[37m# Save the entire model to a HDF5 file\u001b[39;49;00m\r\n",
      "    \u001b[37m#print('Saving the model ....')\u001b[39;49;00m\r\n",
      "    transformer.save_weights(os.path.join(args.sm_model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtransformer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), overwrite=\u001b[34mTrue\u001b[39;49;00m, save_format=\u001b[33m'\u001b[39;49;00m\u001b[33mtf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[37m#transformer.save_weights(args.sm_model_dir, overwrite=True, save_format='tf')\u001b[39;49;00m\r\n",
      "    \u001b[37m# Save the parameters used to construct the model\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving the model parameters\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    model_info_path = os.path.join(args.sm_model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_info.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_info_path, \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        model_info = {\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mvocab_size_enc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: num_words_inputs,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mvocab_size_dec\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: num_words_output,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33msos_token_input\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: sos_token_input,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33meos_token_input\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: eos_token_input,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33msos_token_output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: sos_token_output,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33meos_token_output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: eos_token_output,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mn_layers\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.n_layers,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33md_model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.d_model,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mffn_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.ffn_dim,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mn_heads\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.n_heads,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mdrop_rate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.dropout_rate\r\n",
      "        }\r\n",
      "        pickle.dump(model_info, f)\r\n",
      "          \r\n",
      "\t\u001b[37m# Save the tokenizers with the vocabularies\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mSaving the dictionaries ....\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    vocabulary_in = os.path.join(args.sm_model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33min_vocab.pkl\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(vocabulary_in, \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        pickle.dump(tokenizer_inputs, f)\r\n",
      "\r\n",
      "    vocabulary_out = os.path.join(args.sm_model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mout_vocab.pkl\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(vocabulary_out, \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        pickle.dump(tokenizer_outputs, f)\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize 'train/train.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a training job using the `TensorFlow` estimator\n",
    "\n",
    "The `sagemaker.tensorflow.TensorFlow` estimator handles locating the script mode container, uploading your script to a S3 location and creating a SageMaker training job. Let's call out a couple important parameters here:\n",
    "\n",
    "* `py_version` is set to `'py3'` to indicate that we are using script mode since legacy mode supports only Python 2. Though Python 2 will be deprecated soon, you can use script mode with Python 2 by setting `py_version` to `'py2'` and `script_mode` to `True`.\n",
    "\n",
    "* `distributions` is used to configure the distributed training setup. It's required only if you are doing distributed training either across a cluster of instances or across multiple GPUs. Here we are using parameter servers as the distributed training schema. SageMaker training jobs run on homogeneous clusters. To make parameter server more performant in the SageMaker setup, we run a parameter server on every instance in the cluster, so there is no need to specify the number of parameter servers to launch. Script mode also supports distributed training with [Horovod](https://github.com/horovod/horovod). You can find the full documentation on how to configure `distributions` [here](https://github.com/aws/sagemaker-python-sdk/tree/master/src/sagemaker/tensorflow#distributed-training). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also initiate an estimator to train with TensorFlow 2.1 script. The only things that you will need to change are the script name and ``framewotk_version``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instance_type='ml.m5.xlarge'\n",
    "instance_type='ml.m4.4xlarge'\n",
    "#instance_type='local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "estimator = TensorFlow(entry_point='train.py',\n",
    "                       source_dir=\"train\",\n",
    "                       role=role,\n",
    "                       train_instance_count=1,\n",
    "                       train_instance_type=instance_type,\n",
    "                       framework_version='2.1.0',\n",
    "                       py_version='py3',\n",
    "                       output_path=output_data_uri,\n",
    "                       base_job_name='tf-transformer',\n",
    "                       script_mode= True,\n",
    "                       #checkpoint_local_path = 'ckpt',\n",
    "                       checkpoint_s3_uri = ckpt_data_uri,\n",
    "                       hyperparameters={\n",
    "                        'epochs': 1,\n",
    "                        'nsamples': 5000,\n",
    "                        'train_file': 'spa.txt',\n",
    "                        'non_breaking_in': 'nonbreaking_prefix.en',\n",
    "                        'non_breaking_out': 'nonbreaking_prefix.es'\n",
    "                       })\n",
    "                       #distributions={'parameter_server': {'enabled': False}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling ``fit``\n",
    "\n",
    "To start a training job, we call `estimator.fit(training_data_uri)`.\n",
    "\n",
    "An S3 location is used here as the input. `fit` creates a default channel named `'training'`, which points to this S3 location. In the training script we can then access the training data from the location stored in `SM_CHANNEL_TRAINING`. `fit` accepts a couple other types of input as well. See the API doc [here](https://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.EstimatorBase.fit) for details.\n",
    "\n",
    "When training starts, the TensorFlow container executes mnist.py, passing `hyperparameters` and `model_dir` from the estimator as script arguments. Because we didn't define either in this example, no hyperparameters are passed, and `model_dir` defaults to `s3://<DEFAULT_BUCKET>/<TRAINING_JOB_NAME>`, so the script execution is as follows:\n",
    "```bash\n",
    "python mnist.py --model_dir s3://<DEFAULT_BUCKET>/<TRAINING_JOB_NAME>\n",
    "```\n",
    "When training is complete, the training job will upload the saved model for TensorFlow serving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling fit to train a model with TensorFlow 2.1 scroipt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-07 17:49:03 Starting - Starting the training job...\n",
      "2020-11-07 17:49:05 Starting - Launching requested ML instances......\n",
      "2020-11-07 17:50:15 Starting - Preparing the instances for training......\n",
      "2020-11-07 17:51:04 Downloading - Downloading input data...\n",
      "2020-11-07 17:51:55 Training - Training image download completed. Training in progress..\u001b[34m2020-11-07 17:52:00,541 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-11-07 17:52:00,547 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-11-07 17:52:01,905 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-11-07 17:52:01,923 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-11-07 17:52:01,940 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-11-07 17:52:01,953 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"non_breaking_out\": \"nonbreaking_prefix.es\",\n",
      "        \"nsamples\": 5000,\n",
      "        \"train_file\": \"spa.txt\",\n",
      "        \"model_dir\": \"s3://edumunozsala-ml-sagemaker/transformer-nmt/tf-transformer-2020-11-07-17-49-03-516/model\",\n",
      "        \"non_breaking_in\": \"nonbreaking_prefix.en\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tf-transformer-2020-11-07-17-49-03-516\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://edumunozsala-ml-sagemaker/tf-transformer-2020-11-07-17-49-03-516/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1,\"model_dir\":\"s3://edumunozsala-ml-sagemaker/transformer-nmt/tf-transformer-2020-11-07-17-49-03-516/model\",\"non_breaking_in\":\"nonbreaking_prefix.en\",\"non_breaking_out\":\"nonbreaking_prefix.es\",\"nsamples\":5000,\"train_file\":\"spa.txt\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://edumunozsala-ml-sagemaker/tf-transformer-2020-11-07-17-49-03-516/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"model_dir\":\"s3://edumunozsala-ml-sagemaker/transformer-nmt/tf-transformer-2020-11-07-17-49-03-516/model\",\"non_breaking_in\":\"nonbreaking_prefix.en\",\"non_breaking_out\":\"nonbreaking_prefix.es\",\"nsamples\":5000,\"train_file\":\"spa.txt\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tf-transformer-2020-11-07-17-49-03-516\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://edumunozsala-ml-sagemaker/tf-transformer-2020-11-07-17-49-03-516/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\",\"--model_dir\",\"s3://edumunozsala-ml-sagemaker/transformer-nmt/tf-transformer-2020-11-07-17-49-03-516/model\",\"--non_breaking_in\",\"nonbreaking_prefix.en\",\"--non_breaking_out\",\"nonbreaking_prefix.es\",\"--nsamples\",\"5000\",\"--train_file\",\"spa.txt\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_NON_BREAKING_OUT=nonbreaking_prefix.es\u001b[0m\n",
      "\u001b[34mSM_HP_NSAMPLES=5000\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_FILE=spa.txt\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://edumunozsala-ml-sagemaker/transformer-nmt/tf-transformer-2020-11-07-17-49-03-516/model\u001b[0m\n",
      "\u001b[34mSM_HP_NON_BREAKING_IN=nonbreaking_prefix.en\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 train.py --epochs 1 --model_dir s3://edumunozsala-ml-sagemaker/transformer-nmt/tf-transformer-2020-11-07-17-49-03-516/model --non_breaking_in nonbreaking_prefix.en --non_breaking_out nonbreaking_prefix.es --nsamples 5000 --train_file spa.txt\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mCollecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.1.0-py3-none-any.whl (3.6 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.18.1)\u001b[0m\n",
      "\u001b[34mCollecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting dill\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.22.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-0.25.0-py3-none-any.whl (44 kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm\n",
      "  Downloading tqdm-4.51.0-py2.py3-none-any.whl (70 kB)\u001b[0m\n",
      "\u001b[34mCollecting dataclasses; python_version < \"3.7\"\n",
      "  Downloading dataclasses-0.7-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting typing-extensions; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.1.0)\u001b[0m\n",
      "\u001b[34mCollecting importlib-resources; python_version < \"3.9\"\n",
      "  Downloading importlib_resources-3.3.0-py2.py3-none-any.whl (26 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.14.0)\u001b[0m\n",
      "\u001b[34mCollecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (3.11.3)\u001b[0m\n",
      "\u001b[34mCollecting attrs>=18.1.0\n",
      "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.25.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2020.4.5.1)\u001b[0m\n",
      "\u001b[34mCollecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow_datasets) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow_datasets) (46.1.3)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: promise, future\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21495 sha256=9d8c0408327fe579911cfed5429bd46d570d601d4c726782569658edfa776aee\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/9a/1d/3f1afbbb5122d0410547bf9eb50955f4a7a98e53a6d8b99bd1\n",
      "  Building wheel for future (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=17c21c2d4365bc9988f2932ef128efd2efb0d17adaeb5418fced3ac57f9a9d39\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/9c/ed/4499c9865ac1002697793e0ae05ba6be33553d098f3347fb94\u001b[0m\n",
      "\u001b[34mSuccessfully built promise future\u001b[0m\n",
      "\u001b[34mInstalling collected packages: promise, dill, googleapis-common-protos, tensorflow-metadata, tqdm, dataclasses, typing-extensions, importlib-resources, future, attrs, tensorflow-datasets\u001b[0m\n",
      "\u001b[34mSuccessfully installed attrs-20.3.0 dataclasses-0.7 dill-0.3.3 future-0.18.2 googleapis-common-protos-1.52.0 importlib-resources-3.3.0 promise-2.3 tensorflow-datasets-4.1.0 tensorflow-metadata-0.25.0 tqdm-4.51.0 typing-extensions-3.7.4.3\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m/opt/ml/model s3://edumunozsala-ml-sagemaker/transformer-nmt/tf-transformer-2020-11-07-17-49-03-516/model\u001b[0m\n",
      "\u001b[34mGet the train data\u001b[0m\n",
      "\u001b[34mGet the train data loader.\u001b[0m\n",
      "\u001b[34mTokenize the input and output data and create the vocabularies\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mInput vocab:  1976\u001b[0m\n",
      "\u001b[34mOutput vocab:  3865\u001b[0m\n",
      "\u001b[34mCreating the checkpoint ...\u001b[0m\n",
      "\u001b[34mTraining the model ....\u001b[0m\n",
      "\u001b[34mStarting epoch 1\u001b[0m\n",
      "\u001b[34mEpoch 1 Batch 0 Loss 2.7229 Accuracy 0.0000\u001b[0m\n",
      "\u001b[34mSaving checkpoint for epoch 1 in /opt/ml/checkpoints/ckpt-1\u001b[0m\n",
      "\u001b[34mSaving the model parameters\u001b[0m\n",
      "\u001b[34mSaving the dictionaries ....\u001b[0m\n",
      "\u001b[34m2020-11-07 17:52:48,200 sagemaker_tensorflow_container.training WARNING  Your model will NOT be servable with SageMaker TensorFlow Serving container. The model artifact was not saved in the TensorFlow SavedModel directory structure:\u001b[0m\n",
      "\u001b[34mhttps://www.tensorflow.org/guide/saved_model#structure_of_a_savedmodel_directory\u001b[0m\n",
      "\u001b[34m2020-11-07 17:52:48,200 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-11-07 17:52:59 Uploading - Uploading generated training model\n",
      "2020-11-07 17:52:59 Completed - Training job completed\n",
      "Training seconds: 115\n",
      "Billable seconds: 115\n"
     ]
    }
   ],
   "source": [
    "#estimator.fit({'training':training_data_uri,'testing':testing_data_uri})\n",
    "estimator.fit({'training':training_data_uri})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach a previous training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-07 16:40:41 Starting - Preparing the instances for training\n",
      "2020-11-07 16:40:41 Downloading - Downloading input data\n",
      "2020-11-07 16:40:41 Training - Training image download completed. Training in progress.\n",
      "2020-11-07 16:40:41 Uploading - Uploading generated training model\n",
      "2020-11-07 16:40:41 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "# Set the training job you want to attach to the estimator object\n",
    "my_training_job_name = 'tf-transformer-2020-11-07-16-35-42-885'\n",
    "# Attach the estimator to the selected training job\n",
    "estimator = TensorFlow.attach(my_training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf-transformer-2020-11-07-17-49-03-516'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.latest_training_job.job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://edumunozsala-ml-sagemaker/transformer-nmt/tf-transformer-2020-11-07-17-49-03-516/output/model.tar.gz\n",
      "edumunozsala-ml-sagemaker\n"
     ]
    }
   ],
   "source": [
    "print(estimator.model_data)\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DownLoad the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's3_output_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cd43af2edf34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minference_results_bucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0minference_results_bucket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3_output_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_inference_results_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 's3_output_key' is not defined"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "inference_results_bucket = s3.Bucket(bucket_name)\n",
    " \n",
    "inference_results_bucket.download_file(s3_output_key, local_inference_results_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_path='transformer-nmt/tf-transformer-2020-11-07-17-49-03-516/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.download_data(trainedmodel_path,bucket_name,s3_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, extract the information out from the model.tar.gz file return by the training job in SageMaker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.index\n",
      "out_vocab.pkl\n",
      "model_info.pth\n",
      "in_vocab.pkl\n",
      "checkpoint\n",
      "transformer.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "!tar -zxvf $trainedmodel_path/model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the tensorflow model and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.model import Transformer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to restore the parameters of the model we have saved in order to build an instance of the Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters {'vocab_size_enc': 1976, 'vocab_size_dec': 3865, 'sos_token_input': [1974], 'eos_token_input': [1975], 'sos_token_output': [3863], 'eos_token_output': [3864], 'n_layers': 4, 'd_model': 64, 'ffn_dim': 128, 'n_heads': 8, 'drop_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Read the parameters from a dictionary\n",
    "#model_info_path = os.path.join(model_dir, 'model_info.pth')\n",
    "with open(model_info_file, 'rb') as f:\n",
    "    model_info = pickle.load(f)\n",
    "print('Model parameters',model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of the Transforer model and load the saved model to th\n",
    "transformer = Transformer(vocab_size_enc=model_info['vocab_size_enc'],\n",
    "                          vocab_size_dec=model_info['vocab_size_dec'],\n",
    "                          d_model=model_info['d_model'],\n",
    "                          n_layers=model_info['n_layers'],\n",
    "                          FFN_units=model_info['ffn_dim'],\n",
    "                          n_heads=model_info['n_heads'],\n",
    "                          dropout_rate=model_info['drop_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4be38f4668>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load thr saved model\n",
    "transformer.load_weights('transformer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-datasets\n",
      "  Using cached tensorflow_datasets-4.1.0-py3-none-any.whl (3.6 MB)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow-datasets) (4.42.1)\n",
      "Processing /home/ec2-user/.cache/pip/wheels/59/9a/1d/3f1afbbb5122d0410547bf9eb50955f4a7a98e53a6d8b99bd1/promise-2.3-py3-none-any.whl\n",
      "Collecting tensorflow-metadata\n",
      "  Using cached tensorflow_metadata-0.25.0-py3-none-any.whl (44 kB)\n",
      "Collecting dataclasses; python_version < \"3.7\"\n",
      "  Using cached dataclasses-0.7-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow-datasets) (19.3.0)\n",
      "Collecting importlib-resources; python_version < \"3.9\"\n",
      "  Using cached importlib_resources-3.3.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting typing-extensions; python_version < \"3.8\"\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow-datasets) (1.18.1)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow-datasets) (0.18.2)\n",
      "Requirement already satisfied: absl-py in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow-datasets) (0.11.0)\n",
      "Collecting dill\n",
      "  Using cached dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow-datasets) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow-datasets) (3.8.0)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow-datasets) (1.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow-datasets) (2.22.0)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Using cached googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n",
      "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets) (2.2.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow-datasets) (45.2.0.post20200210)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow-datasets) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow-datasets) (2020.6.20)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow-datasets) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.0.4)\n",
      "\u001b[31mERROR: tensorflow-metadata 0.25.0 has requirement absl-py<0.11,>=0.9, but you'll have absl-py 0.11.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: promise, googleapis-common-protos, tensorflow-metadata, dataclasses, importlib-resources, typing-extensions, dill, tensorflow-datasets\n",
      "Successfully installed dataclasses-0.7 dill-0.3.3 googleapis-common-protos-1.52.0 importlib-resources-3.3.0 promise-2.3 tensorflow-datasets-4.1.0 tensorflow-metadata-0.25.0 typing-extensions-3.7.4.3\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow2_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install the library necessary to tokenize the sentences\n",
    "!pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from serve.predict import translate\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the input and output tokenizer or vocabularis used in the training. We need them to encode and decode the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the parameters from a dictionary\n",
    "#model_info_path = os.path.join(model_dir, 'model_info.pth')\n",
    "with open(input_vocab_file, 'rb') as f:\n",
    "    tokenizer_inputs = pickle.load(f)\n",
    "\n",
    "with open(output_vocab_file, 'rb') as f:\n",
    "    tokenizer_outputs = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: you should pay for it.\n",
      "Output sentence: \n"
     ]
    }
   ],
   "source": [
    "#Show some translations\n",
    "sentence = \"you should pay for it.\"\n",
    "print(\"Input sentence: {}\".format(sentence))\n",
    "predicted_sentence = translate(transformer,sentence,tokenizer_inputs, tokenizer_outputs,15,model_info['sos_token_input'],\n",
    "                               model_info['eos_token_input'],model_info['sos_token_output'],\n",
    "                               model_info['eos_token_output'])\n",
    "print(\"Output sentence: {}\".format(predicted_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deploy the trained model to an endpoint\n",
    "\n",
    "The `deploy()` method creates a SageMaker model, which is then deployed to an endpoint to serve prediction requests in real time. We will use the TensorFlow Serving container for the endpoint, because we trained with script mode. This serving container runs an implementation of a web server that is compatible with SageMaker hosting protocol. The [Using your own inference code]() document explains how SageMaker runs inference containers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Deployed the trained TensorFlow 2.1 model to an endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error hosting endpoint tf-transformer-2020-11-06-16-29-07-384: Failed. Reason:  The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint..",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0d1b68be025b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, use_compiled_model, update_endpoint, wait, model_name, kms_key, data_capture_config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0mdata_capture_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         )\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/tensorflow/serving.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, update_endpoint, tags, kms_key, wait, data_capture_config)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mdata_capture_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, update_endpoint, tags, kms_key, wait, data_capture_config)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             )\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict)\u001b[0m\n\u001b[1;32m   2903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m   2423\u001b[0m         )\n\u001b[1;32m   2424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2425\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2426\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mendpoint_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mwait_for_endpoint\u001b[0;34m(self, endpoint, poll)\u001b[0m\n\u001b[1;32m   2692\u001b[0m                 ),\n\u001b[1;32m   2693\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"InService\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2694\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2695\u001b[0m             )\n\u001b[1;32m   2696\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error hosting endpoint tf-transformer-2020-11-06-16-29-07-384: Failed. Reason:  The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.."
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoke the endpoint\n",
    "\n",
    "Let's download the training data and use that as input for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the prediction result from the TensorFlow 2.1 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-5daal_1  |\u001b[0m 2020/03/28 21:14:44 [info] 11#11: *1 client 172.18.0.1 closed keepalive connection\r\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(test_file, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_class</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   encoded_class  sepal_length  sepal_width  petal_length  petal_width\n",
       "0              1           5.8          2.7           4.1          1.0\n",
       "1              0           4.8          3.4           1.6          0.2\n",
       "2              1           6.0          2.2           4.0          1.0\n",
       "3              2           6.4          3.1           5.5          1.8\n",
       "4              2           6.7          2.5           5.8          1.8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.8 2.7 4.1 1. ]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.7 2.5 5.8 1.8]]\n"
     ]
    }
   ],
   "source": [
    "X_test = df.iloc[:,1:].values\n",
    "print(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-5daal_1  |\u001b[0m 172.18.0.1 - - [28/Mar/2020:21:14:44 +0000] \"POST /invocations HTTP/1.1\" 200 2039 \"-\" \"-\"\r\n"
     ]
    }
   ],
   "source": [
    "result = predictor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result =  result['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.00026031278, 0.990563631, 0.00917605218],\n",
       " [0.999760091, 0.000239968373, 3.97464422e-10],\n",
       " [0.000185193509, 0.974752605, 0.0250621513],\n",
       " [9.90088935e-08, 0.241644651, 0.758355319],\n",
       " [1.86230598e-09, 0.0252015758, 0.974798381]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_class'] = np.argmax(result,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_class</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   encoded_class  sepal_length  sepal_width  petal_length  petal_width  \\\n",
       "0              1           5.8          2.7           4.1          1.0   \n",
       "1              0           4.8          3.4           1.6          0.2   \n",
       "2              1           6.0          2.2           4.0          1.0   \n",
       "3              2           6.4          3.1           5.5          1.8   \n",
       "4              2           6.7          2.5           5.8          1.8   \n",
       "\n",
       "   predicted_class  \n",
       "0                1  \n",
       "1                0  \n",
       "2                1  \n",
       "3                2  \n",
       "4                2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Class Labels to integers\n",
    "# Labeled Classes\n",
    "labels=[0,1,2]\n",
    "classes = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Confusion Matrix</h2>\n",
    "Confusion Matrix is a table that summarizes performance of classification model.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: \n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    #else:\n",
    "    #    print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(df['encoded_class'],\n",
    "                              df['predicted_class'],labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  0,  0],\n",
       "       [ 0, 10,  1],\n",
       "       [ 0,  0, 18]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=classes,\n",
    "                      title='Confusion matrix - Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=classes,\n",
    "                      title='Confusion matrix - Count',normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        16\n",
      "Iris-versicolor       1.00      0.91      0.95        11\n",
      " Iris-virginica       0.95      1.00      0.97        18\n",
      "\n",
      "       accuracy                           0.98        45\n",
      "      macro avg       0.98      0.97      0.98        45\n",
      "   weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(\n",
    "    df['encoded_class'],\n",
    "    df['predicted_class'],\n",
    "    labels=labels,\n",
    "    target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete the endpoint\n",
    "\n",
    "Let's delete the endpoint we just created to prevent incurring any extra costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the TensorFlow 2.1 endpoint as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "estimator.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy model using artifacts\n",
    "https://sagemaker.readthedocs.io/en/stable/using_tf.html#deploy-to-a-sagemaker-endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.serving import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://chandra-ml-sagemaker/iris/model/tf-iris-2020-03-28-21-14-26-369/model.tar.gz'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmp81b25ulb_algo-1-oufpd_1\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m INFO:__main__:starting services\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m INFO:__main__:using default model name: model\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m INFO:__main__:tensorflow serving model config: \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m model_config_list: {\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m   config: {\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     name: \"model\",\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     base_path: \"/opt/ml/model\",\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     model_platform: \"tensorflow\"\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m   }\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m }\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m INFO:__main__:nginx config: \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m load_module modules/ngx_http_js_module.so;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m worker_processes auto;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m daemon off;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m pid /tmp/nginx.pid;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m error_log  /dev/stderr error;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m worker_rlimit_nofile 4096;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m events {\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m   worker_connections 2048;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m }\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m http {\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m   include /etc/nginx/mime.types;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m   default_type application/json;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m   access_log /dev/stdout combined;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m   js_include tensorflow-serving.js;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m   upstream tfs_upstream {\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     server localhost:8501;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m   }\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m   upstream gunicorn_upstream {\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     server unix:/tmp/gunicorn.sock fail_timeout=1;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m   }\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m   server {\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     listen 8080 deferred;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     client_max_body_size 0;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     client_body_buffer_size 100m;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     subrequest_output_buffer_size 100m;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     set $tfs_version 2.1;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     set $default_tfs_model model;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     location /tfs {\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m         rewrite ^/tfs/(.*) /$1  break;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m         proxy_redirect off;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m         proxy_pass_request_headers off;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m         proxy_set_header Content-Type 'application/json';\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m         proxy_set_header Accept 'application/json';\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m         proxy_pass http://tfs_upstream;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     }\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     location /ping {\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m         js_content ping_without_model;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     }\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     location /invocations {\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m         js_content invocations;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     }\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     location ~ ^/models/(.*)/invoke {\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m         js_content invocations;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     }\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     location /models {\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m         proxy_pass http://gunicorn_upstream/models;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     }\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     location / {\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m         return 404 '{\"error\": \"Not Found\"}';\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     }\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m     keepalive_timeout 3;\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m   }\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m }\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m INFO:__main__:tensorflow version info:\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m TensorFlow ModelServer: 2.1.0-rc1+dev.sha.d81097a\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m TensorFlow Library: 2.1.0\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m INFO:__main__:tensorflow serving command: tensorflow_model_server --port=9000 --rest_api_port=8501 --model_config_file=/sagemaker/model-config.cfg --max_num_load_retries=0 \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m INFO:__main__:started tensorflow serving (pid: 9)\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m INFO:__main__:nginx version info:\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m nginx version: nginx/1.16.1\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m built by gcc 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1) \r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m built with OpenSSL 1.1.1  11 Sep 2018\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m TLS SNI support enabled\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m configure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-g -O2 -fdebug-prefix-map=/data/builder/debuild/nginx-1.16.1/debian/debuild-base/nginx-1.16.1=. -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie'\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m INFO:__main__:started nginx (pid: 11)\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.296775: I tensorflow_serving/model_servers/server_core.cc:462] Adding/updating models.\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.296799: I tensorflow_serving/model_servers/server_core.cc:573]  (Re-)adding model: model\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.397030: I tensorflow_serving/util/retrier.cc:46] Retrying of Reserving resources for servable: {name: model version: 1} exhausted max_num_retries: 0\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.397050: I tensorflow_serving/core/basic_manager.cc:739] Successfully reserved resources to load servable {name: model version: 1}\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.397064: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: model version: 1}\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.397077: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: model version: 1}\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.397139: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /opt/ml/model/000000001\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.398442: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.398466: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:264] Reading SavedModel debug info (if present) from: /opt/ml/model/000000001\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.398535: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.399313: I external/org_tensorflow/tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.420029: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:203] Restoring SavedModel bundle.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.461390: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:152] Running initialization op on SavedModel bundle at path: /opt/ml/model/000000001\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.465019: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:333] SavedModel load for tags { serve }; Status: success: OK. Took 67894 microseconds.\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.465400: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /opt/ml/model/000000001/assets.extra/tf_serving_warmup_requests\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.465666: I tensorflow_serving/util/retrier.cc:46] Retrying of Loading servable: {name: model version: 1} exhausted max_num_retries: 0\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.465686: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: model version: 1}\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.467364: I tensorflow_serving/model_servers/server.cc:362] Running gRPC ModelServer at 0.0.0.0:9000 ...\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m [warn] getaddrinfo: address family for nodename not supported\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 2020-03-28 21:14:57.468324: I tensorflow_serving/model_servers/server.cc:382] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m [evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\n",
      "!\u001b[36malgo-1-oufpd_1  |\u001b[0m 172.18.0.1 - - [28/Mar/2020:21:15:01 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"-\"\n"
     ]
    }
   ],
   "source": [
    "model = Model(model_data=model_data, role=role,framework_version='2.1.0')\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.8, 2.7, 4.1, 1. ],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-oufpd_1  |\u001b[0m 172.18.0.1 - - [28/Mar/2020:21:15:01 +0000] \"POST /invocations HTTP/1.1\" 200 254 \"-\" \"-\"\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': [[0.00026031278, 0.990563631, 0.00917605218],\n",
       "  [0.999760091, 0.000239968373, 3.97464422e-10],\n",
       "  [0.000185193509, 0.974752605, 0.0250621513],\n",
       "  [9.90088935e-08, 0.241644651, 0.758355319],\n",
       "  [1.86230598e-09, 0.0252015758, 0.974798381]]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
